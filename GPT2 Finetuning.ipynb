{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1GUqMfxOX1Wu_N65JisonjURx2GVR7B7r","authorship_tag":"ABX9TyNN9/nQLKOVVV17tfCofp9O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"G3-WJaeuWzK-"},"outputs":[],"source":["!pip install -q transformers"]},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AdamW\n","import torch\n","from tqdm import tqdm  # Import tqdm\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer\n","from IPython.display import FileLink\n","import pandas as pd\n","from transformers import set_seed"],"metadata":{"id":"-7u8c43hmIPQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n","\n","# add the EOS token as PAD token to avoid warnings\n","model = AutoModelForCausalLM.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id).to(torch_device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A6l39viKXH66","executionInfo":{"status":"ok","timestamp":1723477947873,"user_tz":-180,"elapsed":9717,"user":{"displayName":"Omar Mo3ty","userId":"15747352296675518605"}},"outputId":"7feb7006-428c-44b0-da97-eb437b6b67c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["### ***Greedy***"],"metadata":{"id":"wsD38zZvwjS3"}},{"cell_type":"code","source":["# encode context the generation is conditioned on\n","model_inputs = tokenizer('I was taking a bath then', return_tensors='pt').to(torch_device)\n","\n","# generate 40 new tokens\n","greedy_output = model.generate(**model_inputs, max_new_tokens=40)\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))\n"],"metadata":{"id":"kAdJoA1tXkWG","executionInfo":{"status":"ok","timestamp":1723469008744,"user_tz":-180,"elapsed":1236,"user":{"displayName":"Omar Mo3ty","userId":"15747352296675518605"}},"outputId":"991205d2-75e7-4151-ab3c-fc958bb65590","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","I was taking a bath then I heard a noise. I looked up and saw a man in a white shirt and a black shirt. I looked up and saw a man in a white shirt and a black shirt. I looked up\n"]}]},{"cell_type":"markdown","source":["### ***Top K***"],"metadata":{"id":"YOsxxGw5wl8E"}},{"cell_type":"code","source":["model_inputs = tokenizer('I went to school', return_tensors='pt').to(torch_device)\n","sample_outputs = model.generate(\n","    **model_inputs,\n","    max_new_tokens=40,\n","    do_sample=True,\n","    top_k=50,\n","    top_p=0.95,\n","    num_return_sequences=3,\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","for i, sample_output in enumerate(sample_outputs):\n","  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sbpBNQ60vBhb","executionInfo":{"status":"ok","timestamp":1723465092213,"user_tz":-180,"elapsed":2906,"user":{"displayName":"Omar Mo3ty","userId":"15747352296675518605"}},"outputId":"a3c68281-c86e-41e2-9af3-51e9939410f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","0: I went to school, and went back to work and stayed here to see if there were anything we could do. But my father said, 'Look, you can't. You're going to be living in the suburbs\n","1: I went to school,\" he says, laughing nervously.\n","\n","He's had a little break in the last year, and as a young man who does not have any family on him, Mr Thompson decided to change course\n","2: I went to school, had a really good first college in town, got my degree, got up in the morning and then went out and bought myself a coffee,\" said his mom. \"I'm kind of a coffee\n"]}]},{"cell_type":"markdown","source":["### ***Training***"],"metadata":{"id":"Xl1wrkAMw4fF"}},{"cell_type":"code","source":["from transformers import TextDataset, DataCollatorForLanguageModeling\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","from transformers import Trainer, TrainingArguments"],"metadata":{"id":"E4ZXSCmc_mXa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import GPT2Tokenizer\n","import pandas as pd\n","\n","# # Load the dataset\n","dataset = pd.read_json(\"hf://datasets/MuskumPillerum/General-Knowledge/output.json\")\n","dataset['text'] = dataset.apply(lambda row: f\"Q: {row['Question']}  A: {row['Answer']}\", axis=1)\n","\n","# Save the preprocessed data to a text file\n","preprocessed_file_name = 'preprocessed_data.txt'\n","dataset['text'].to_csv(preprocessed_file_name, index=False, header=False)\n","\n","print(\"Tokenized data has been saved.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uFnC1-2nwo5D","executionInfo":{"status":"ok","timestamp":1723477975223,"user_tz":-180,"elapsed":5590,"user":{"displayName":"Omar Mo3ty","userId":"15747352296675518605"}},"outputId":"c6873e09-ddb8-4ede-d86f-d339bd9d7a7e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized data has been saved.\n"]}]},{"cell_type":"code","source":["def load_dataset(file_path, tokenizer, block_size = 128):\n","    dataset = TextDataset(\n","        tokenizer = tokenizer,\n","        file_path = file_path,\n","        block_size = block_size,\n","    )\n","    return dataset\n","\n","\n","def load_data_collator(tokenizer, mlm = False):\n","    data_collator = DataCollatorForLanguageModeling(\n","        tokenizer=tokenizer,\n","        mlm=mlm,\n","    )\n","    return data_collator\n","\n","\n","def train(train_file_path,model_name,\n","          output_dir,\n","          overwrite_output_dir,\n","          per_device_train_batch_size,\n","          num_train_epochs,\n","          save_steps):\n","  tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","  train_dataset = load_dataset(train_file_path, tokenizer)\n","  data_collator = load_data_collator(tokenizer)\n","\n","  tokenizer.save_pretrained(output_dir)\n","\n","  model = GPT2LMHeadModel.from_pretrained(model_name)\n","\n","  model.save_pretrained(output_dir)\n","\n","  training_args = TrainingArguments(\n","          output_dir=output_dir,\n","          overwrite_output_dir=overwrite_output_dir,\n","          per_device_train_batch_size=per_device_train_batch_size,\n","          num_train_epochs=num_train_epochs,\n","      )\n","\n","  trainer = Trainer(\n","          model=model,\n","          args=training_args,\n","          data_collator=data_collator,\n","          train_dataset=train_dataset,\n","  )\n","\n","  trainer.train()\n","  trainer.save_model()"],"metadata":{"id":"NY0S5On6_mpx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# you need to set parameters\n","train_file_path = \"/content/preprocessed_data.txt\"\n","model_name = 'gpt2'\n","output_dir = '/content/drive/MyDrive/result'\n","overwrite_output_dir = False\n","per_device_train_batch_size = 128\n","num_train_epochs = 10\n","save_steps = 1000"],"metadata":{"id":"9Zevmr7i_rRp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train(\n","    train_file_path=train_file_path,\n","    model_name=model_name,\n","    output_dir=output_dir,\n","    overwrite_output_dir=overwrite_output_dir,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    num_train_epochs=num_train_epochs,\n","    save_steps=save_steps\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yHo00WV-ECMh","outputId":"7105e829-a2f8-46e5-9715-13dcf6bd1e30"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["### ***Prediction***"],"metadata":{"id":"nPFCdvfjw_Se"}},{"cell_type":"code","source":["model_dir = '/content/drive/MyDrive/result'\n","# Load the fine-tuned model and tokenizer\n","model = AutoModelForCausalLM.from_pretrained(model_dir).to(torch_device)\n","tokenizer = AutoTokenizer.from_pretrained(model_dir)"],"metadata":{"id":"tS1f1yl9HxuQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# encode context the generation is conditioned on\n","model_inputs = tokenizer('Person A: Hi, how was your day?', return_tensors='pt').to(torch_device)\n","\n","# set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n","sample_outputs = model.generate(\n","    **model_inputs,\n","    max_new_tokens=150,\n","    do_sample=True,\n","    top_k=50,\n","    top_p=0.95,\n","    num_return_sequences=3,\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","for i, sample_output in enumerate(sample_outputs):\n","  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CjdoMIWclr34","executionInfo":{"status":"ok","timestamp":1723467970555,"user_tz":-180,"elapsed":3927,"user":{"displayName":"Omar Mo3ty","userId":"15747352296675518605"}},"outputId":"824cf419-f780-4fb3-ea25-214e3622ab03"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","0: Person A: Hi, how was your day?\n","Q: hi, how was your day? || A: i got really good at school.\n","Q: i got really good at school. || A: i'm not good at math.\n","Q: i'm not good at math. || A: well, your grades have gone up.\n","Q: well, your grades have gone up. || A: you should probably do something else. you're such a talented student.\n","Q: what did you do at school? || A: i went to chinese restaurant.\n","Q: i went to chinese restaurant. || A: did you like it?\n","Q: did you like it? || A: i loved it! how about yourself?\n","Q: i\n","1: Person A: Hi, how was your day?\n","Q: hi, how was your day? || A: my best was 100!\n","\"Q: my best was 100! || A: that's amazing, thank you. i really wish i had never met you.\"\n","\"Q: that's amazing, thank you. i really wish i had never met you. || A: you know me too, i wish i had. sometimes it's fun to meet new people.\"\n","Q: you know me too, i wish i had never met you. || A: of course i wish i had met you before.\n","Q: of course i wish i had met you before. || A: what happened?\n","Q: what happened? || A: i got married.\n","\n","2: Person A: Hi, how was your day?\n","Q: hi, how was your day? || A: i'm sorry.\n","Q: i'm sorry. || A: i had a nervous breakdown.\n","Q: i had a nervous breakdown. || A: i'm sorry. your stomach was bothering you.\n","\"Q: i'm sorry. your stomach was bothering you. || A: i took something that you shouldn't take, like a pill or a medicine pill.\"\n","\"Q: i took something that you shouldn't take, like a pill or a medicine pill. || A: i took something that was too much for you.\"\n","Q: i took something that was too much for you. || A: what did you do?\n","Q: what did you\n"]}]}]}